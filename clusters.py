import kneed
import sklearn
import numpy as np
from kneed import KneeLocator
from sklearn.cluster import KMeans
from collections import Counter
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
import pandas as pd
import matplotlib.pyplot as plt
from collections import defaultdict
from matplotlib.colors import ListedColormap


# Create function that runs kmeans with a range of clusters with the data, test the accuracy (inertia) of different cluster numbers representing the raw data using the elbow method, return the optimal number of clusters

def K(data, max_k = 11, plot = False):
    """
    input data. function approximates optimal number of clusters using elbow method and returns this value
    """
    inertias = []
    for i in range(1,max_k):
        kmeans = KMeans(n_clusters=i)
        kmeans.fit(data)
        inertias.append(kmeans.inertia_)

    kl = KneeLocator(range(1, max_k), inertias, curve="convex", direction="decreasing")
    if plot :
        kl.plot_knee()
    return kl.elbow


# normalize data
def normalize(data) :
	'''Normalize data so each column has a mean of 0 and a standard deviation of 1'''
	return (data - np.mean(data, axis=0)) / np.std(data, axis=0)

# Create function that plots kmeans data based on the data and elbow method
def plotKMeans(data, labels1a, labels2 = None): 
    """"
    input data,
    returns plot of data color-coded by labels1; If labels2 is specified, we use 'x' to indicate a difference between label    values (e.g., incorrect classification)
    
    """

    date = np.array(data)
    x, y = date.T
    
    labels1b = pd.factorize(labels1a)
    labels1 = labels1b[0]

    if np.any(labels2 == None):
       plt.scatter(x,y,c = labels1)
       return None
    
    assignedDict = labelClusters(labels1, labels2)
    assigned = [assignedDict[l] for l in labels1]
    correct = np.array(assigned) == np.array(labels2)
    wrong = np.logical_not(correct)

    fig, ax = plt.subplots()
    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']
    i = 0
    for s in set(labels1) :
        index = np.logical_and(correct, labels1 == s)
        ax.scatter(x[index], y[index], c=colors[i], label = assignedDict[s])
    
        index = np.logical_and(wrong, labels1 == s)
        ax.scatter(x[index], y[index], c=colors[i], label = '_no_legend_', marker = 'x')
    
        i+= 1
    
    handles, labels = plt.gca().get_legend_handles_labels()
    order = np.argsort(labels)
    ax.legend([handles[idx] for idx in order],[labels[idx] for idx in order]) 
    plt.show()


def labelClusters(klabels, labels, print_df = False):
    """
    enter the arbitrary labels generated by kmeans and the true labels. This function returns a disctionary telling you
    which kmeans cluster is most associated with which true label.
    """
    # create default dictionary with default an empty list
    # the key is the klabel and the value is the list of values for that label
    counters = defaultdict(list)

    # for each klabel and label
    for k, l in zip(klabels, labels) :    
        # add the label to the dictionary
        counters[k] += [l]
        
    # count the number of values for each klabel
    for k in counters :
        counters[k] = Counter(counters[k])
    counters
    
    # create a dictionary of clusterLabels based on the most common value for each klabel
    clusterLabels = {}
    for k in counters:
        c = counters[k]
        clusterLabels[k] = c.most_common(1)[0][0]
        
    return clusterLabels


def getClusters(data, labels):
    """"
    input: data, labels
    returns tuple: cluster labels, number of clusters
    
    """
    
    y = K(data)
    gSList = set(labels)
    glist = []
    for x in gSList:
        glist.append(x)
    glist.append(y)
    v = tuple(glist)
    return v

def randIndex(klabels, labels):
    """"
    input: klabels, labels
    
    uses true cluster labels to measure accuracy of kmeans on data. rand index takes compares 
    how well the predicted clusters and the true clusters line up. 
    
    return rand index
    """
    score = sklearn.metrics.rand_score(klabels, labels)
    
    return score 

def use_kmeans(data, labels, k = 0):
    """
    enter data and labels as np arrays. You can also specify a the number of clusters but otherwise this will be computed with the elbow method. This function preforms kmeans on the data and then compares the arbitrary
    cluster labels to the true labels, giving the rand index. This function returns the kmeans object, the rand index 
    and the number of clusters as a tuple in that order.
    """
    
    if k==0:
        k = K(data)
     
    kmeans = KMeans(n_clusters=k)
    kmeans.fit(data)
    
    return kmeans, randIndex(kmeans.labels_, labels)

    """
def importData(data, labels):
    ""
    enter name of data file in csv format, enter name of labels file in csv format. Make sure both files are local so they 
    can be directly called. This function spits out a tuple with a 2D numpy array of the data first and a 1D array of the 
    labels second.
    ""
    data = pd.read_csv(data, 
                    header=0, sep='\t+', engine='python')
    labelz = pd.read_csv(labels, header = 0)
    labels = np.array(labelz.iloc[:, 0])

    dlist = []
    for x in range(len(data)):
        dlist.append(list(data.loc[x]))
    darr = np.array(dlist)
    """
    
def import_data(data_file, labels_file, label_column='tumor'):
    """
    Enter name of data file and labels file in TSV format. 
    Make sure both files are in the same local directory so they can be directly called. 
    This function returns a tuple with a 2D numpy array of the data first and a 1D array of the labels second.

    Parameters:
    data_file (str): Name of the data TSV file
    labels_file (str): Name of the labels TSV file
    label_column (str): Name of the column to use as labels

    Returns:
    tuple: A tuple containing a 2D numpy array of the data and a 1D array of the labels
    """
    try:
        data = pd.read_csv(data_file, header=0, sep='\t', index_col=0, engine='python')
        data = data.transpose() # transpose the data so that each sample is a row, not a column
        labels_df = pd.read_csv(labels_file, header=0, sep='\t', index_col=0, engine='python')
        labels = labels_df[label_column].values
        return data.values, labels
    except FileNotFoundError:
        print("File not found. Please check the file name and directory.")
        return None
    except Exception as e:
        print("Error reading file: ", e)
        return None
    
    return data, labels

def mapSoms(som, labels, data, n_neurons, m_neurons):
    """
    This function takes as an input: the som object, the labels, date, nueron number height, nueron number length.
    The function returns a distance map where each block is a nueron and each unique colored symbol represent a BMU
    """
    label_set = set(labels)
    label_dict = dict(zip(label_set, range(len(label_set))))
    target = np.array([label_dict[label] for label in labels])
    
    # Define the colormap with as many colors as there are unique labels
    colors = ['C{}'.format(i) for i in range(len(np.unique(labels)))]
    cmap = ListedColormap(colors)

    # Create the plot
    plt.figure(figsize=(n_neurons, m_neurons))
    plt.pcolor(som.distance_map().T, cmap='bone_r')  # plotting the distance map as background
    plt.colorbar()

    # Plotting the response for each pattern in the dataset
    markers = ['o', 's', 'D', '^', 'v', '<', '>', 'p', '*', 'h', 'H', 'd']
    for cnt, xx in enumerate(data):
        w = som.winner(xx)
        # place a marker on the winning position for the sample xx
        plt.plot(w[0]+.5, w[1]+.5, markers[target[cnt] % len(markers)], markerfacecolor='None',
             markeredgecolor=colors[target[cnt]], markersize=12, markeredgewidth=2)

    plt.show()